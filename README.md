# Resume Analyzer

A FastAPI-based application that extracts resume content and analyzes it against a job description using Ollama.

## Features
- PDF/DOCX resume text extraction
- LLM-based skill matching and recommendations
- STAR-based interview prep
- Project highlights and learning path suggestions

**ğŸ§  Step-by-Step Guide: Running Resume Analyzer with Ollama + FastAPI + Gradio**<br>
âœ… 1. **Install Ollama**<br>
Ollama lets you run large language models (LLMs) like OpenChat locally.<br>
Install Ollama: **https://ollama.com/download**<br>
Download and install for your OS (macOS, Windows, or Linux).
After installing, make sure ollama is accessible via terminal:
**ollama --version**

âœ… 2. **Pull the OpenChat model**<br>
Run the following in your terminal:
**ollama run openchat**<br>
This will:
Download the OpenChat model<br>
Start an interactive shell (you can Ctrl+C to exit after confirming it works)

âœ… 3. R**un your FastAPI backend**<br>
Navigate to your projectâ€™s backend/ directory (where main.py is):<br>

**cd project-folder<br>
uvicorn main:app --reload**<br>
This starts the FastAPI server at:
**ğŸ“ http://127.0.0.1:8000**<br>
Make sure Ollama is still running and listening at http://localhost:11434.

âœ… 4. **Run the Gradio Frontend UI**<br>
In another terminal (still in the backend/ folder), run:
**python ui.py**<br>
This will launch the Gradio interface locally. Youâ€™ll get a link like:<br>
Running on local URL:  **http://127.0.0.1:7860/**

**ğŸ§ª Testing Flow**<br>
ollama run openchat â€” load the LLM<br>
uvicorn main:app --reload â€” start API server<br>
python ui.py â€” start Gradio UI<br>
Open the Gradio link â†’ upload your resume + paste job description â†’ receive analy<br>
